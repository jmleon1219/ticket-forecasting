{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exterior-canyon",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import engine\n",
    "import numpy as np\n",
    "import matplotlib.pyplot\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pursuant-headquarters",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng = engine.create_engine(rs_url, connect_args={'connect_timeout': 24 * 60 * 60, 'sslmode': 'allow'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retired-bench",
   "metadata": {},
   "outputs": [],
   "source": [
    "tkt_df = pd.read_sql(\"\"\"\n",
    "                             with games as(\n",
    "                                     \t  select distinct event_cod\n",
    "                                      \t    from dw.ticket_fac tf \n",
    "                                      inner join dw.event_dim ed on tf.event_id = ed.event_id \n",
    "                                      inner join dw.date_dim edt on tf.event_date_id = edt.date_id \n",
    "                                      inner join dw.date_dim sdt on tf.sale_date_id = sdt.date_id\n",
    "                                     group by ed.event_cod \t\t  \n",
    "                                     having count(*) > 3000\n",
    "                                     \t and count(distinct date_part(day,sdt.full_date)) > 20\n",
    "                                    \torder by count(*) )\n",
    "                              select ed.event_cod,\n",
    "                                        case substring(ed.event_cod,3,1) \n",
    "                                            when 'W' THEN 'WNT'\n",
    "                                            when 'M' THEN 'MNT'\n",
    "                                        end as team,\n",
    "                             \t  \t sum(tf.ticket_cnt) as tkt_sold,\n",
    "                             \t  \t cast(date_part(day,sdt.full_date) as int) as sold_days_b4_game\n",
    "                              \t    from dw.ticket_fac tf \n",
    "                              inner join dw.event_dim ed on tf.event_id = ed.event_id \n",
    "                              inner join dw.date_dim edt on tf.event_date_id = edt.date_id \n",
    "                              inner join dw.date_dim sdt on tf.sale_date_id = sdt.date_id\n",
    "                              inner join games on games.event_cod = ed.event_cod\n",
    "                             group by ed.event_cod,\n",
    "                             \t\t\tdate_part(day,sdt.full_date),\n",
    "                                          case substring(ed.event_cod,3,1) \n",
    "                                            when 'W' THEN 'WNT'\n",
    "                                            when 'M' THEN 'MNT'\n",
    "                                        end\n",
    "                                        order by event_cod, date_part(day,sdt.full_date) desc\"\"\"\n",
    "                    , con=eng.connect())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reduced-sacramento",
   "metadata": {},
   "outputs": [],
   "source": [
    "tkt_df = pd.concat([tkt_df, pd.get_dummies(tkt_df.team)], axis=1).drop(\"team\", axis=1).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "awful-directive",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tkt_df = tkt_df.loc[~(tkt_df.event_cod.isin([\"19W1110\", \"15W0920\", \"18M0907\", \"19M0605\", \"18W1010\", \"19M1011\"]) ) & ~(tkt_df['event_cod'].str.contains(\"C\"))].reset_index(drop=True).sort_values([\"event_cod\",\"sold_days_b4_game\"], ascending=False).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finite-alias",
   "metadata": {},
   "outputs": [],
   "source": [
    "tkt_sub_df = tkt_df[tkt_df.event_cod.isin([\"19M0605\"])].sort_values(\"sold_days_b4_game\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comic-financing",
   "metadata": {},
   "outputs": [],
   "source": [
    "tkt_sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italian-title",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt = all_tkt_df.pivot(columns='event_cod', values='tkt_sold').plot()\n",
    "plt.invert_xaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compound-comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOT NEEDED TO RUN, THE TRAINING IS THE OLD GAMES\n",
    "\n",
    "test= tkt_sub_df.reset_index(drop=True)\n",
    "train = all_tkt_df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solved-harrison",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, OrdinalEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_transformer, make_column_selector\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "X_scaler = StandardScaler()\n",
    "y_scaler = MinMaxScaler()\n",
    "scaler_out = MinMaxScaler()\n",
    "\n",
    "oe = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "\n",
    "b = y_scaler.fit_transform(train['tkt_sold'].to_numpy().reshape(-1,1))\n",
    "c = X_scaler.fit_transform(train['sold_days_b4_game'].to_numpy().reshape(-1,1))\n",
    "\n",
    "train_enc = pd.concat((\n",
    "                         pd.DataFrame(b)\n",
    "                        ,pd.DataFrame(c)\n",
    "                        ,train.iloc[:,-2:])\n",
    "                        , axis=1).to_numpy()\n",
    "\n",
    "train_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appointed-essex",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premium-adobe",
   "metadata": {},
   "outputs": [],
   "source": [
    "length=7\n",
    "batch_size=25\n",
    "features=4\n",
    "model = Sequential()\n",
    "model.add(LSTM(128\n",
    "              ,return_sequences=True\n",
    "              ,activation='relu'\n",
    "              ,batch_input_shape =(batch_size, length, features)))\n",
    "#model.add(Dropout(0.1))\n",
    "model.add(LSTM(312 \n",
    "             ,return_sequences=True\n",
    "              ,activation='relu'\n",
    "              ))\n",
    "model.add(LSTM(256 \n",
    "             ,return_sequences=True\n",
    "              ,activation='relu'\n",
    "              ))\n",
    "#model.add(Dropout(0.1))\n",
    "model.add(LSTM(128\n",
    "                ,return_sequences=True\n",
    "                ,activation='relu'))\n",
    "model.add(LSTM(64 \n",
    "               ,activation='relu'\n",
    "                ,return_sequences=False))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grand-guatemala",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "american-capture",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stop = EarlyStopping(monitor = 'val_loss', patience = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hispanic-automation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frozen-migration",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = TimeseriesGenerator(train_enc, train_enc[:,0].reshape(-1,1,1), length=12, batch_size=25) \n",
    "len(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turned-middle",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the length of the generator is 85, batch is 25, what is the length\n",
    "'''\n",
    "generator = 85\n",
    "batch = 25\n",
    "total_length_of_data = 2132\n",
    "then length =7\n",
    "\n",
    "length = total_length_of_data -(generator * batch)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alike-measure",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = TimeseriesGenerator(train_enc, train_enc[:,0].reshape(-1,1,1), length=length, batch_size=batch_size) \n",
    "    \n",
    "    \n",
    "model.fit(generator\n",
    "      ,epochs=15000\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lightweight-arbitration",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = pd.DataFrame(model.history.history)\n",
    "loss.plot(figsize=(15,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biological-authorization",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_weights= model.get_weights()\n",
    "\n",
    "length=7\n",
    "batch_size=1\n",
    "features=4\n",
    "n_model = Sequential()\n",
    "n_model.add(LSTM(128\n",
    "              ,return_sequences=True\n",
    "              ,activation='relu'\n",
    "              ,batch_input_shape =(batch_size, length, features)))\n",
    "#model.add(Dropout(0.1))\n",
    "n_model.add(LSTM(312 \n",
    "             ,return_sequences=True\n",
    "              ,activation='relu'\n",
    "              ))\n",
    "n_model.add(LSTM(256 \n",
    "             ,return_sequences=True\n",
    "              ,activation='relu'\n",
    "              ))\n",
    "#model.add(Dropout(0.1))\n",
    "n_model.add(LSTM(128\n",
    "                ,return_sequences=True\n",
    "                ,activation='relu'))\n",
    "n_model.add(LSTM(64 \n",
    "               ,activation='relu'\n",
    "                ,return_sequences=False))\n",
    "n_model.add(Dense(1))\n",
    "\n",
    "n_model.set_weights(old_weights)\n",
    "n_model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italian-reset",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst=tkt_df.loc[tkt_df.event_cod == '19W1110'].sort_values(\"sold_days_b4_game\", ascending=False)\n",
    "\n",
    "b1 = y_scaler.transform(tst['tkt_sold'].to_numpy().reshape(-1,1))\n",
    "c1 = X_scaler.transform(tst['sold_days_b4_game'].to_numpy().reshape(-1,1))\n",
    "\n",
    "\n",
    "tst_enc = pd.concat([\n",
    "                        pd.DataFrame(b1), \n",
    "                        pd.DataFrame(c1),\n",
    "                        tst.iloc[:,-2:].reset_index(drop=True)],\n",
    "                            axis=1).to_numpy()\n",
    "\n",
    "\n",
    "x = tst_enc[-(length+15):-15]\n",
    "\n",
    "tst_enc\n",
    "\n",
    "pred = n_model.predict(x.reshape(-1,length,features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pointed-enhancement",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst.iloc[-(length+15):-14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "undefined-killer",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scaler.inverse_transform(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medium-europe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scaler.inverse_transform(x[:,0].reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mediterranean-surveillance",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_scaler.transform((tst.iloc[-2][1]).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absent-boost",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_enc[-15:-8].reshape((-1, length, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annoying-reference",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = []\n",
    "current_batch = None\n",
    "\n",
    "first_eval_batch = tst_enc[-22:(-22+length)]\n",
    "current_batch = first_eval_batch.reshape((1, length, features))\n",
    "\n",
    "for i in range(15):\n",
    "    z=16+i\n",
    "    \n",
    "    # get prediction 1 time stamp ahead ([0] is for grabbing just the number instead of [array])\n",
    "    current_pred = n_model.predict(current_batch)[0]\n",
    "    \n",
    "    # store prediction\n",
    "    test_predictions.append([current_pred[0], tst_enc[z][1], tst_enc[z][2], tst_enc[z][3]])\n",
    "    \n",
    "    # update batch to now include prediction and drop first value\n",
    "    current_batch = np.append(current_batch[:,1:,:], np.asarray([current_pred[0], tst_enc[z][1], tst_enc[z][2], tst_enc[z][3]]).reshape(1,1,features), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inappropriate-bosnia",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tst_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nonprofit-start",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df =pd.concat(\n",
    "        [pd.DataFrame(y_scaler.inverse_transform(np.asarray(test_predictions)[:,0].reshape(-1,1))),\n",
    "        pd.DataFrame(X_scaler.inverse_transform(np.asarray(test_predictions)[:,1].reshape(-1,1)))]\n",
    "    ,axis=1\n",
    ")\n",
    "pred_df.columns = [\"sales\", \"days_left\"]\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dietary-nigeria",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.plot(x=\"days_left\").invert_xaxis()\n",
    "\n",
    "tst.loc[tst.sold_days_b4_game < 16].drop([\"MNT\",\"WNT\"], axis=1).rename(columns={\"sold_days_b4_game\":\"days_left\"}).plot(x=\"days_left\").invert_xaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standard-revolution",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
